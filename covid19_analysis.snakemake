import os,sys,glob

if not os.path.exists("config.yaml"):
        print("Error:config.yaml not found. Exiting!")
        exit(1)
if not os.path.exists("list.txt"):
        print("Error:list.txt not found. You can create list.txt from"\
              "runinfo file using srainfo.sh")
        exit(1)

configfile: 'config.yaml'
SINGLE_SRR=[]
PAIRED_SRR=[]
SPECIES_SRR={}
SPECIES_GSM={}
GSM_SINGLE_DICT={}
GSM_PAIRED_DICT={}

specieslist = config["specieslist"]
"""
Input list.txt should be in this format:
SRR306834	SINGLE	Pan_paniscus	RNA-Seq	cDNA	GSM752687
SRR306835	SINGLE	Pan_paniscus	RNA-Seq	cDNA	GSM752688
SRR306836	SINGLE	Pan_paniscus	RNA-Seq	cDNA	GSM752689
SRR306837	SINGLE	Pan_paniscus	RNA-Seq	cDNA	GSM752690
SRR306838	SINGLE	Homo_sapiens	RNA-Seq	cDNA	GSM752691
SRR306839	SINGLE	Homo_sapiens	RNA-Seq	cDNA	GSM752692
SRR306840	PAIRED	Homo_sapiens	RNA-Seq	cDNA	GSM752693
First 3 columns are mandatory. if only first 3 columns are given
then GSE columsn is assumed to be same as the first column and
all samples are assumed to be be "RNA-Seq"
"""

for line in open("list.txt"):
        if line!="\n" and line != "":
                elements = line.strip().split("\t")
                elements[2] = elements[2].replace(" ","_")
                #print(line,str(len(elements)))
                if len(elements) == 6 and elements[3].upper() == "RNA-SEQ":
                        if elements[2] not in specieslist:
                                print("*****NOT FOUND:",elements[0],elements[2])
                                continue
                        if elements[1].upper() == "SINGLE":
                                SINGLE_SRR.append(elements[0])
                                SPECIES_SRR[elements[0]]=elements[2]
                                SPECIES_GSM[elements[5]]=elements[2]
                                try:
                                        GSM_SINGLE_DICT[elements[5]].append(elements[0])
                                except KeyError:
                                        GSM_SINGLE_DICT[elements[5]]=[]
                                        GSM_SINGLE_DICT[elements[5]].append(elements[0])
                        elif elements[1].upper() == "PAIRED":
                                PAIRED_SRR.append(elements[0])
                                SPECIES_SRR[elements[0]]=elements[2]
                                SPECIES_GSM[elements[5]]=elements[2]
                                try:
                                        GSM_PAIRED_DICT[elements[5]].append(elements[0])
                                except KeyError:
                                        GSM_PAIRED_DICT[elements[5]]=[]
                                        GSM_PAIRED_DICT[elements[5]].append(elements[0])
                elif len(elements) == 3:
                        if elements[2] not in specieslist:
                                print("*****NOT FOUND:",elements[0],elements[2])
                                continue
                        if elements[1].upper() == "SINGLE":
                                SINGLE_SRR.append(elements[0])
                                SPECIES_SRR[elements[0]]=elements[2]
                                SPECIES_GSM[elements[0]]=elements[2]
                                try:
                                        GSM_SINGLE_DICT[elements[0]].append(elements[0])
                                except KeyError:
                                        GSM_SINGLE_DICT[elements[0]]=[]
                                        GSM_SINGLE_DICT[elements[0]].append(elements[0])
                        elif elements[1].upper() == "PAIRED":
                                PAIRED_SRR.append(elements[0])
                                SPECIES_SRR[elements[0]]=elements[2]
                                SPECIES_GSM[elements[0]]=elements[2]
                                try:
                                        GSM_PAIRED_DICT[elements[0]].append(elements[0])
                                except KeyError:
                                        GSM_PAIRED_DICT[elements[0]]=[]
                                        GSM_PAIRED_DICT[elements[0]].append(elements[0])
ALL_SRR = SINGLE_SRR + PAIRED_SRR
GSM_SINGLE_DICT_KEYS = list(GSM_SINGLE_DICT.keys())
GSM_PAIRED_DICT_KEYS = list(GSM_PAIRED_DICT.keys())

print("Single end:\n",SINGLE_SRR,"\nGSM single dict:")
print(GSM_SINGLE_DICT)
print("======================\n")
print("Paired end:\n",PAIRED_SRR,"\nGSM paired dict:")
print(GSM_PAIRED_DICT)
print("======================\n")

print("GSM single keys:\n",GSM_SINGLE_DICT_KEYS)
print("\nGSM paired keys:\n",GSM_PAIRED_DICT_KEYS)
#print("All libs:\n",ALL_SRR)

def hisat2_single_input(wildcards):
    return(["data/{}_trimmed.fq.gz".format(srr) for srr in SINGLE_SRR])

rule all:
    input:
        "qualityreport/multiqc_report.html",
        expand('data/{sample}_trimmed.fq.gz',sample=SINGLE_SRR),
        "outputs/covid19_kraken2_out.txt","outputs/covid19_krona.html",
        "bams/covid19_complete.bam",
        "bams/covid19.bam", "outputs/covid19_flagstats.txt",
        "covid19_picardstats.alignment_summary_metrics",
        "outputs/covid19_consensus.fa","quast_output/report.html"
rule fastqdump_paired:
    input:
        "data/{sample}.sra"
    output:
        file1 = temp("data/{sample}_1.fastq.gz"),
        file2 = temp("data/{sample}_2.fastq.gz")
    params:
        "data"
    message:
        "Running fastqdump on paired: {wildcards.sample}"
    shell:
        """
        fastq-dump --gzip --skip-technical --split-3  --dumpbase {input} -O {params}
        """
rule fastqdump_single:
    input:
        "data/{sample}.sra"
    output:
        file1 = "data/{sample}.fastq.gz"
    message:
        "Running fastqdump on single: {wildcards.sample}"
    params:
        "data"
    shell:
        """
        fastq-dump --gzip --skip-technical --dumpbase {input} -O {params}
        """
rule fastqc_paired:
    input:
        mate1 = "data/{sample}_1.fastq.gz",
        mate2 = "data/{sample}_2.fastq.gz"
    output:
        output1 = "quality/{sample}_1_fastqc.html",
        output2 = "quality/{sample}_2_fastqc.html"
    message:
        "Running paired fastqc on paired: {wildcards.sample}"
    shell:
        """
        fastqc {input.mate1} {input.mate2} -o quality
        """
rule fastqc_single:
    input:
        'data/{sample}.fastq.gz'
    output:
        'quality/{sample}_fastqc.html'
    message:
        "Running single fastqc on single:{wildcards.sample}"
    shell:
        """
        fastqc {input} -o quality
        """
rule multiqc:
        input:
                expand("quality/{sample}_fastqc.html",sample=SINGLE_SRR),
                expand("quality/{sample}_1_fastqc.html",sample=PAIRED_SRR),
        output:
                "qualityreport/multiqc_report.html"
        message:
                "Running multiqc"
        shell:
                """
                multiqc quality -o qualityreport
                """
rule trim_adapters_paired:
        input:
                mate1 = 'data/{sample}_1.fastq.gz',
                mate2 = 'data/{sample}_2.fastq.gz'
        output:
                f1 = 'data/{sample}_1_trimmed.fq.gz',
                f2 = 'data/{sample}_2_trimmed.fq.gz',
                f1_unpaired = 'data/{sample}_1_trimmed_unpaired.fq.gz',
                f2_unpaired = 'data/{sample}_2_trimmed_unpaired.fq.gz'
        threads: 4
        message:
                "Executing trimming on paired-end:{wildcards.sample}."
        log:
                "logs/{sample}.trim.log"
        shell:
                r"""
                trimmomatic PE -phred33 -threads {threads} -trimlog {log} \
                {input.mate1} {input.mat2} {output.f1} {output.f1_unpaired} \
                {output.f2} {output.f2_unpaired} \
                ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:keepBothReads LEADING:3 \
                TRAILING:3 MINLEN:36
                """
rule trim_adapters_single:
        input:
                'data/{sample}.fastq.gz'
        output:
                'data/{sample}_trimmed.fq.gz'
        threads: 4
        message:
                "Executing trimming on single end:{wildcards.sample}."
        log:
                "logs/{sample}.trim.log"
        shell:
                r"""
                trimmomatic SE -phred33 -trimlog {log} {input} {output} \
                ILLUMINACLIP:TruSeq3-SE:2:30:10 LEADING:3 TRAILING:3 \
                SLIDINGWINDOW:4:15 MINLEN:36
                """
rule kraken2_single:
    input:
        expand("data/{sample}_trimmed.fq.gz",sample=SINGLE_SRR)
    threads:4
    params:
        kraken2_db=config["kraken2_db"]
    output:
        report="outputs/covid19_kraken2_report.txt",
        out="outputs/covid19_kraken2_out.txt"
    shell:
        r"""
        kraken2 --gzip-compressed --db {params.kraken2_db} --threads 4 \
        --report {output.report} {input} --output {output.out}
        """
rule krona_single:
    input:
        "outputs/covid19_kraken2_out.txt"
    output:
        "outputs/covid19_krona.html"
    params:
        temp = "outputs/covid19_kraken.korna"
    shell:
        r"""
        cut -f2,3 {input} > {params.temp} && \
        ktImportTaxonomy  {params.temp} -o {output}
        """
rule hisat2_maphuman_single:
    input:
        expand("data/{sample}_trimmed.fq.gz",sample=SINGLE_SRR)
    params:
        inputlist = hisat2_single_input,
        index = config["Homo_sapiens_hisat2index"]
    threads:4
    log: "logs/covid19_mapping_log.txt"
    output: "bams/covid19_complete.bam"
    run:
        if len(params.inputlist) >= 1:
            infiles = ','.join(params.inputlist)
            print(infiles)
            shell(r"""hisat2 -x {params.index} -p {threads} -U {infiles} \
            --dta-cufflinks --summary-file {log}|samtools sort -@ \
            {threads} - -o {output} -O BAM""")
"""
For single end data one can use
samtools view -b -f 4 bams/covid19_complete.bam | \
samtools sort -@ 4  -n - -o bams/newtest.bam -O BAM
"""
rule create_unmappedbam:
    input: "bams/covid19_complete.bam"
    output:
        bam="bams/unmapped.bam",
        t1 = temp("bams/temp1.bam"),
        t2 = temp("bams/temp2.bam"),
        t3 = temp("bams/temp3.bam")
    threads:4
    shell:
        r"""
        samtools view -u -f 4 -F 264 {input} > {output.t1} && \
        samtools view -u -f 8 -F 260 {input} > {output.t2} && \
        samtools view -u -f 12 -F 256 {input} > {output.t3} && \
        samtools merge -@ {threads} -u - bams/temps[123].bam|samtools sort \
        -@ {threads} -n - -o {output.bam} -O BAM
        """
rule create_unmappedfastq:
    input:"bams/unmapped.bam"
    output:
        fq="bams/unmapped.fq"
    shell:
        r"""
        bamToFastq -i {input} -fq {output}
        """
rule hisat2_mapcovid_single:
    input:
        "bams/unmapped.fq"
    params:
        index = config["Severe_acute_respiratory_syndrome_coronavirus_2_hisat2index"]
    threads:4
    log: "logs/covid19_covidmapping_log.txt"
    output: "bams/covid19.bam"
    shell:
        r"""
        hisat2 -x {params.index} -p {threads} -U {input} \
            --dta-cufflinks --summary-file {log}|samtools sort -@ \
            {threads} - -o {output} -O BAM
        """
rule map_stats:
    input: "bams/covid19.bam"
    output: "outputs/covid19_flagstats.txt"
    shell:
        r"""
        samtools flagstat {input} > {output}
        """
rule picard_stats:
    input: "bams/covid19.bam"
    output: "covid19_picardstats.alignment_summary_metrics"
    params:
        outname = "covid19_picardstats",
        genome = config["Severe_acute_respiratory_syndrome_coronavirus_2_genome"]
    shell:
        r"""
        picard CollectMultipleMetrics I={input} \
        O={params.outname} R={params.genome}
        """
rule create_bcf:
    input: "bams/covid19.bam"
    output: "outputs/covid19.bcf"
    params:
        genome = config["Severe_acute_respiratory_syndrome_coronavirus_2_genome"]
    shell:
        r"""
        samtools faidx {params.genome}
        bcftools mpileup --max-depth 1000  -Ou -f {params.genome} {input}|\
        bcftools call --ploidy 1 -mv -Ob -o {output}
        """
rule filter_bcf:
    input: "outputs/covid19.bcf"
    output: "outputs/covid19_norm_filtindels.bcf"
    params:
        genome =config["Severe_acute_respiratory_syndrome_coronavirus_2_genome"],
        norm = "outputs/covid19_norm.bcf"
    shell:
        r"""
        bcftools norm -f {params.params} {input} -Ob -o {params.norm} && \
        bcftools filter --IndelGap 5  {params.norm} -Ob -o {output} && \
        bcftools index {output}
        """
rule create_consensus:
    input: "outputs/covid19_norm_filtindels.bcf"
    output: "outputs/covid19_consensus.fa"
    params:
        genome =config["Severe_acute_respiratory_syndrome_coronavirus_2_genome"]
    shell:
        r"""
        bcftools consensus -f {params.params} {input} > {output}
        """
rule runmegahit:
    input: "bams/unmapped.fq"
    output: "assembly/denovo_covid19_megahit/final.contigs.fa"
    params: "assembly/denovo_covid19_megahit"
    threads: 4
    shell:
        r"""
        megahit -r {input} --min-count 3 -t {threads} -o {params}
        """
rule runspade:
    input: "bams/unmapped.fq",
    output: "assembly/denovo_covid19_spades/contigs.fasta"
    params: "assembly/denovo_covid19_spades"
    threads: 4
    shell:
        r"""
        spades.py -t {threads} -o {params}  -s {input}
        """
rule runspade_isolate:
    input: "bams/unmapped.fq",
    output: "assembly/denovo_covid19_spades_isolate/contigs.fasta"
    params: "assembly/denovo_covid19_spades_isolate"
    threads: 4
    shell:
        r"""
        spades.py -t {threads} --isolate -o {params}  -s {input}
        """
rule runquast:
    input:
        m1 = "assembly/denovo_covid19_megahit/final.contigs.fa",
        m2 = "assembly/denovo_covid19_spades/contigs.fasta",
        m3 = "assembly/denovo_covid19_spades_isolate/contigs.fasta"
    output: "quast_output/report.html"
    params:
        out = "quast_output",
        l1 = "mega",
        l2 = "spade",
        l3 = "spade_isolate",
        genome=config["Severe_acute_respiratory_syndrome_coronavirus_2_genome"]
    threads:4
    shell:
        r"""
        quast.py -o {params.out} -r {params.genome} -t 4 -m 1000 -l \
        "{params.l1},{params.l2},{params.l3}" {input.m1} {input.m2} {input.m3}
        """
